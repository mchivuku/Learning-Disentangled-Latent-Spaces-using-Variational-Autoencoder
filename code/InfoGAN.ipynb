{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ug3UJoX7mVYU"
   },
   "source": [
    "# InfoGAN\n",
    "\n",
    "Notebook contains implementation for InfoGAN - https://arxiv.org/abs/1606.03657\n",
    "\n",
    "Code adapted from: https://github.com/eriklindernoren/Pytorch-GAN/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "isb8LS8-S1bR"
   },
   "source": [
    "## Connect to google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "527spdi5mjJL"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install tqdm six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "fc6nEA_HmmCs",
    "outputId": "2a0e403b-01b1-4287-c518-e60aafb72441"
   },
   "outputs": [],
   "source": [
    "\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "5RvxHBPamqk8",
    "outputId": "7b9a557d-1c54-425f-a9bd-62dc6f6ac3e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Masters-DS/CSCI-B659/project/examples/infoGAN\n",
      "\u001b[0m\u001b[01;34mresults\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/My\\ Drive/Masters-DS/CSCI-B659/project/examples/infoGAN\n",
    "%ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2kaI4PuUm2r8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"infoGAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bi77NZUim9SM",
    "outputId": "9afa8229-3829-48e0-fd56-fae843004335"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Masters-DS/CSCI-B659/project/examples/infoGAN\n"
     ]
    }
   ],
   "source": [
    "%cd infoGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QP6gJFhKm_e9"
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"./results/static\", exist_ok=True)\n",
    "os.makedirs('./results/varying_c1/', exist_ok=True)\n",
    "os.makedirs('./results/varying_c2/', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LBaedON0nSw2"
   },
   "source": [
    "## Torch Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "beEwNN_fnGfM"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import itertools\n",
    "from torch.autograd import Variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Pb9AxT4vnU6d",
    "outputId": "32bc49cf-8606-4d8f-ca1e-e4eaa47f0c27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch 1.0.1.post2 CUDA 10.0.130\n",
      "Device: cuda:0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(5)\n",
    "\n",
    "print('Torch', torch.__version__, 'CUDA', torch.version.cuda)\n",
    "print('Device:', torch.device('cuda:0'))\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device ( \"cuda:0\" if torch.cuda.is_available () else \"cpu\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KE9GmEw0o-24",
    "outputId": "0a9a2e0f-d1df-43b6-c53f-4b018a3fa230"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Params:\n",
    "    n_epochs = 200\n",
    "    batch_size = 128\n",
    "    lr = 0.0002\n",
    "    b1 = 0.5 #adam, decay of first order momentum of gradient\n",
    "    b2 = 0.999 #decay of first order momentum of gradient\n",
    "    n_cpu = 8\n",
    "    latent_dim = 62\n",
    "    code_dim = 2\n",
    "    n_classes = 10\n",
    "    img_size = 32\n",
    "    channels = 1\n",
    "    sample_interval = 400 # interval  between image sampling\n",
    "    \n",
    "    \n",
    "    \n",
    "Params.n_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wN5i7fGgnZBN"
   },
   "outputs": [],
   "source": [
    "## function to initialize weights\n",
    "def weights_init_normal(m):\n",
    "  classname= m.__class__.__name__\n",
    "  if classname.find(\"Conv\")!=-1:\n",
    "    torch.nn.init.normal_(m.weight.data,0.0,0.02)\n",
    "  elif classname.find(\"BatchNorm\")!=-1:\n",
    "    torch.nn.init.normal_(m.weight.data,1.0,0.02)\n",
    "    torch.nn.init.constant_(m.bias.data,0.0)\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "One hot encoded vector for category\n",
    "\"\"\"\n",
    "def to_categorical(y, num_cols):\n",
    "  \"\"\"\n",
    "  \"\"\"\n",
    "  y_cat = np.zeros((y.shape[0],num_cols))\n",
    "  y_cat[range(y.shape[0]),y] =1.\n",
    "  print(y_cat)\n",
    "  return Variable(FloatTensor(y_cat))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lt5Y7HO3oeI-"
   },
   "outputs": [],
   "source": [
    "## Models\n",
    "class Generator(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Generator,self).__init__()\n",
    "    input_dim = Params.latent_dim + Params.n_classes + Params.code_dim\n",
    "    \n",
    "    self.init_size = Params.img_size // 4 #initial size before upsampling\n",
    "    self.l1 = nn.Sequential(nn.Linear(input_dim, \n",
    "                        128*self.init_size **2))\n",
    "    \n",
    "    self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, stride=1,\n",
    "                      padding=1),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1,\n",
    "                      padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, Params.channels, 3,\n",
    "                      stride=1, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "  def forward(self,noise, labels, code):\n",
    "    gen_input = torch.cat((noise, labels, code),-1) \n",
    "    ## include to contains noise and code\n",
    "    out = self.l1(gen_input)\n",
    "    \n",
    "    out = out.view(out.shape[0],128,\n",
    "                   self.init_size, self.init_size)\n",
    "    img = self.conv_blocks(out)\n",
    "    return img\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tbRN8j-1qeJx"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Discriminator,self).__init__()\n",
    "    \n",
    "    def discriminator_block(in_filters, out_filters, bn=True):\n",
    "      \"\"\"Returns layers of each discriminator block\"\"\"\n",
    "      block = [   nn.Conv2d(in_filters, out_filters, 3, 2, 1),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Dropout2d(0.25)]\n",
    "      if bn:\n",
    "        block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
    "      return block\n",
    "          \n",
    "    self.conv_blocks = nn\n",
    "    .Sequential(*discriminator_block(Params.channels,16, bn=False),\n",
    "               *discriminator_block(16,32),\n",
    "               *discriminator_block(32,64),\n",
    "               *discriminator_block(64,128)\n",
    "                )    \n",
    "    \n",
    "    ## height and width of downsampled image\n",
    "    ds_size = Params.img_size // 2**4\n",
    "    self.adv_layer = nn.Sequential(nn.Linear(128*ds_size**2, 1))\n",
    "    self.aux_layer = nn.Sequential(\n",
    "            nn.Linear(128*ds_size**2, Params.n_classes),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "    \n",
    "    self.latent_layer = nn.Sequential(\n",
    "        nn.Linear(128*ds_size**2, Params.code_dim))\n",
    "    \n",
    "  def forward(self, img):\n",
    "      out = self.conv_blocks(img)\n",
    "      out = out.view(out.shape[0], -1)\n",
    "      validity = self.adv_layer(out)\n",
    "      label = self.aux_layer(out)\n",
    "      latent_code = self.latent_layer(out)\n",
    "\n",
    "      return validity, label, latent_code\n",
    "      \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "colab_type": "code",
    "id": "iQA4Ar2Fr7Ll",
    "outputId": "ae18b29a-6cdc-45c3-e371-298f6e49cd04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (l1): Sequential(\n",
      "    (0): Linear(in_features=74, out_features=8192, bias=True)\n",
      "  )\n",
      "  (conv_blocks): Sequential(\n",
      "    (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): Upsample(scale_factor=2, mode=nearest)\n",
      "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): BatchNorm2d(128, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (5): Upsample(scale_factor=2, mode=nearest)\n",
      "    (6): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): BatchNorm2d(64, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (9): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (10): Tanh()\n",
      "  )\n",
      ")\n",
      "\n",
      "Discriminator(\n",
      "  (conv_blocks): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (2): Dropout2d(p=0.25)\n",
      "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (5): Dropout2d(p=0.25)\n",
      "    (6): BatchNorm2d(32, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (8): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (9): Dropout2d(p=0.25)\n",
      "    (10): BatchNorm2d(64, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (12): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (13): Dropout2d(p=0.25)\n",
      "    (14): BatchNorm2d(128, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (adv_layer): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=1, bias=True)\n",
      "  )\n",
      "  (aux_layer): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (1): Softmax()\n",
      "  )\n",
      "  (latent_layer): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## Loss Functions\n",
    "\n",
    "adversarial_loss = torch.nn.MSELoss()\n",
    "categorical_loss = torch.nn.CrossEntropyLoss() \n",
    "# cross entropy loss - discrete loss\n",
    "continuous_loss = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "## Loss weights\n",
    "lambda_cat = 1\n",
    "lambda_con = 0.1\n",
    "\n",
    "## Initialize generator and discriminator netowrk\n",
    "generator  = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "\n",
    "generator = generator.cuda()\n",
    "discriminator = discriminator.cuda()\n",
    "\n",
    "print(generator)\n",
    "print()\n",
    "print(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "colab_type": "code",
    "id": "FWnBsdkksx02",
    "outputId": "53bb24aa-4399-49fb-cf29-7c020cb16311"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (conv_blocks): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (2): Dropout2d(p=0.25)\n",
       "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (5): Dropout2d(p=0.25)\n",
       "    (6): BatchNorm2d(32, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (8): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (9): Dropout2d(p=0.25)\n",
       "    (10): BatchNorm2d(64, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (12): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (13): Dropout2d(p=0.25)\n",
       "    (14): BatchNorm2d(128, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (adv_layer): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       "  (aux_layer): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=10, bias=True)\n",
       "    (1): Softmax()\n",
       "  )\n",
       "  (latent_layer): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Initialize weights\n",
    "# Initialize weights\n",
    "generator.apply(weights_init_normal)\n",
    "discriminator.apply(weights_init_normal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gqF9lDWztOlG"
   },
   "outputs": [],
   "source": [
    "## Data\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../vae/mnist/data', train=True, \n",
    "                   download=True,\n",
    "   transform=transforms.Compose([\n",
    "   transforms.Resize(Params.img_size),\n",
    "   transforms.ToTensor(),\n",
    "   transforms.Normalize((0.5, ), (0.5,))\n",
    "       ])),\n",
    "    batch_size=Params.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jqry-cH_tpKX"
   },
   "outputs": [],
   "source": [
    "## Define Optimizers\n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(),\n",
    "                lr=Params.lr, betas=(Params.b1, Params.b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), \n",
    "                lr=Params.lr, betas=(Params.b1, Params.b2))\n",
    "optimizer_info = torch.optim.Adam(itertools.chain(generator.parameters(),\n",
    "                  discriminator.parameters()),\n",
    "                  lr=Params.lr, betas=(Params.b1, Params.b2))\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor  \n",
    "LongTensor = torch.cuda.LongTensor  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1717
    },
    "colab_type": "code",
    "id": "Nu6k9nDWt5GX",
    "outputId": "98b79fce-39cb-4725-c5f6-9126205b14a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "## Static generator inputs for sampling\n",
    "# Static generator inputs for sampling\n",
    "import numpy as np\n",
    "\n",
    "static_z = Variable(FloatTensor(\n",
    "    np.zeros((Params.n_classes**2, Params.latent_dim))))\n",
    "static_label = to_categorical(\n",
    "    np.array([num for _ in range(Params.n_classes) \n",
    "              for num in range(Params.n_classes)]),\n",
    "             Params.n_classes)\n",
    "static_code = Variable(FloatTensor\n",
    "              (np.zeros((Params.n_classes**2, Params.code_dim))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g54BVXUKuW2I"
   },
   "outputs": [],
   "source": [
    "def sample_image(n_row, batches_done):\n",
    "    \"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\"\n",
    "    # Static sample\n",
    "    z = Variable(FloatTensor(np.random.normal(0, 1,\n",
    "                (n_row**2, Params.latent_dim))))\n",
    "    static_sample = generator(z, static_label, static_code)\n",
    "    save_image(static_sample.data, './results/static/%d.png'\n",
    "               % batches_done, nrow=n_row, normalize=True)\n",
    "\n",
    "    # Get varied c1 and c2\n",
    "    zeros = np.zeros((n_row**2, 1))\n",
    "    c_varied = np.repeat(np.linspace(-1, 1, n_row)[:, np.newaxis], n_row, 0)\n",
    "    c1 = Variable(FloatTensor(np.concatenate((c_varied, zeros), -1)))\n",
    "    c2 = Variable(FloatTensor(np.concatenate((zeros, c_varied), -1)))\n",
    "    sample1 = generator(static_z, static_label, c1)\n",
    "    sample2 = generator(static_z, static_label, c2)\n",
    "    save_image(sample1.data, './results/varying_c1/%d.png'\n",
    "               % batches_done, nrow=n_row, normalize=True)\n",
    "    save_image(sample2.data, './results/varying_c2/%d.png'\n",
    "               % batches_done, nrow=n_row, normalize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FmFAf5GJvH6c"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 883031
    },
    "colab_type": "code",
    "id": "G60CT3uyux_p",
    "outputId": "8c61914e-80d6-48b0-f67c-e5dcc922ee80"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "for epoch in range(Params.n_epochs):\n",
    "  for i, (images,labels) in enumerate(dataloader):\n",
    "    batch_size = images.size(0)\n",
    "    \n",
    "    ## real and fake ground truth\n",
    "    real = Variable(FloatTensor(batch_size,1)\n",
    "                    .fill_(1.0),requires_grad=False)\n",
    "    fake = Variable(FloatTensor(batch_size,1)\n",
    "                    .fill_(0.0),requires_grad=False)\n",
    "    \n",
    "    ## configure input\n",
    "    real_imgs = Variable(images.type(FloatTensor))\n",
    "    labels = Variable(labels.type(FloatTensor))\n",
    "    \n",
    "    ### Train Generator\n",
    "    optimizer_G.zero_grad()\n",
    "    \n",
    "    ## sample noise and labels as generator input\n",
    "    z = Variable(FloatTensor(np.random.normal(0,1,\n",
    "             (batch_size,Params.latent_dim))))\n",
    "    label_input = to_categorical(np.random.randint(0,\n",
    "             Params.n_classes, batch_size),Params.n_classes)\n",
    "    \n",
    "    code_input = Variable(FloatTensor(np.random.uniform(-1,1,\n",
    "                     (batch_size,Params.code_dim))))\n",
    "    \n",
    "    # Generate a batch of images - labels, code and z\n",
    "    gen_imgs = generator(z, label_input, code_input)\n",
    "    \n",
    "    \n",
    "    # discriminator\n",
    "    validity, _, _ = discriminator(gen_imgs)\n",
    "    \n",
    "    g_loss = adversarial_loss(validity,real)\n",
    "    \n",
    "    g_loss.backward()\n",
    "    optimizer_G.step()\n",
    "    \n",
    "    \n",
    "    ##\n",
    "    # Train Discriminator\n",
    "    \n",
    "    optimizer_D.zero_grad()\n",
    "    \n",
    "    ## Loss on real images\n",
    "    real_pred, _, _ = discriminator(real_imgs)\n",
    "    d_real_loss = adversarial_loss(real_pred, real)\n",
    "    \n",
    "    ## Loss on fake images\n",
    "    fake_pred, _, _ = discriminator(gen_imgs.detach())\n",
    "    d_fake_loss = adversarial_loss(fake_pred, fake)\n",
    "    \n",
    "    ## Total discriminator loss\n",
    "    d_loss = (d_real_loss + d_fake_loss)/2\n",
    "    \n",
    "    d_loss.backward()\n",
    "    optimizer_D.step()\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### MutualInformation Loss\n",
    "    ####\n",
    "    \n",
    "    optimizer_info.zero_grad()\n",
    "    \n",
    "    ## sample labels\n",
    "    sampled_labels = np.random.randint(0,Params.n_classes, batch_size)\n",
    "    \n",
    "    # ground truth labels\n",
    "    gt_labels = Variable(LongTensor(sampled_labels),\n",
    "               requires_grad = False)\n",
    "    \n",
    "    \n",
    "    # Sample noise, labels and code as generator input\n",
    "    z = Variable(FloatTensor(np.random.normal(0, 1, \n",
    "                    (batch_size, Params.latent_dim))))\n",
    "    label_input = to_categorical(sampled_labels, Params.n_classes)\n",
    "    code_input = Variable(FloatTensor(\n",
    "        np.random.normal(-1, 1, (batch_size, Params.code_dim))))\n",
    "\n",
    "    gen_imgs = generator(z, label_input, code_input)\n",
    "    _, pred_label, pred_code = discriminator(gen_imgs)\n",
    "    \n",
    "    info_loss = lambda_cat * \n",
    "    categorical_loss(pred_label, gt_labels) + \\\n",
    "                lambda_con * \n",
    "    continuous_loss(pred_code, code_input)\n",
    "    \n",
    "    info_loss.backward()\n",
    "    \n",
    "    optimizer_info.step()\n",
    "    \n",
    "    #--------------\n",
    "    # Log Progress\n",
    "    #--------------\n",
    "\n",
    "    print (\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f] [info loss: %f]\" \n",
    "           % (epoch, Params.n_epochs, i, len(dataloader),\n",
    "           d_loss.item(), g_loss.item(), info_loss.item()))\n",
    "    \n",
    "    \n",
    "    batches_done = epoch * len(dataloader) + i\n",
    "    if batches_done % Params.sample_interval == 0:\n",
    "            sample_image(n_row=10, batches_done=batches_done)\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ekdSG-IyHr9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "InfoGAN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
